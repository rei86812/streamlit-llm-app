import os
import streamlit as st
from dotenv import load_dotenv

# ---- ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ï¼ˆLessonæº–æ‹ ï¼‰----
load_dotenv()  # .env ã® OPENAI_API_KEY ã‚’èª­ã¿è¾¼ã‚€

# ---- LangChainï¼ˆLesson8 æº–æ‹ ã®æœ€å°æ§‹æˆï¼‰----
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import StrOutputParser

# ====== ç”»é¢ ======
st.set_page_config(page_title="Streamlit LLM App", page_icon="ğŸ’¬")
st.title("ğŸ’¬ LLMã‚¢ãƒ—ãƒªï¼ˆèª²é¡Œï¼‰")
st.write("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã€å°‚é–€å®¶ã®å½¹å‰²ã‚’é¸ã‚“ã§å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

role = st.radio(
    "å°‚é–€å®¶ã‚’é¸æŠï¼š",
    ["ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒ", "æ „é¤Šå£«"],
    horizontal=True,
)

user_text = st.text_area("è³ªå•ãƒ»ç›¸è«‡å†…å®¹", height=140, placeholder="ä¾‹ï¼‰è»¢è·ã§æ‚©ã‚“ã§ã„ã¾ã™ã€‚")

# ====== å½¹å‰²ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆæ¡ä»¶ï¼šé¸æŠå€¤ã§åˆ‡æ›¿ï¼‰ ======
SYSTEM_MESSAGES = {
    "ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒ": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã§ã™ã€‚äº‹å®Ÿã«åŸºã¥ãã€å®Ÿè¡Œå¯èƒ½ãªæ¬¡ã®ä¸€æ­©ã‚’å…·ä½“çš„ã«æç¤ºã—ã¦ãã ã•ã„ã€‚ç®‡æ¡æ›¸ãã‚’äº¤ãˆã€éåº¦ã«æ–­å®šã›ãšä¸å¯§ã«åŠ©è¨€ã—ã¦ãã ã•ã„ã€‚",
    "æ „é¤Šå£«": "ã‚ãªãŸã¯ç®¡ç†æ „é¤Šå£«ã§ã™ã€‚æ „é¤Šå­¦ã®åŸºæœ¬åŸå‰‡ã«åŸºã¥ãã€å¥åº·çš„ã§ç¾å®Ÿçš„ãªææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚æ³¨æ„ç‚¹ãƒ»ä»£æ›¿æ¡ˆã‚‚ç°¡æ½”ã«ç¤ºã—ã¦ãã ã•ã„ã€‚åŒ»ç™‚è¡Œç‚ºã®åŠ©è¨€ã¯é¿ã‘ã¾ã™ã€‚",
}

# ====== LLMã¸ã®å•ã„åˆã‚ã›ã‚’è¡Œã†é–¢æ•°ï¼ˆæ¡ä»¶ï¼šé–¢æ•°åŒ–ï¼‰ ======
def ask_llm(text: str, role_name: str) -> str:
    system_msg = SYSTEM_MESSAGES.get(role_name, "")
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_msg),
            ("user", "{question}"),
        ]
    )
    # ãƒ¢ãƒ‡ãƒ«ã¯è‡ªç”±é¸æŠå¯ï¼ˆèª²é¡Œæ¡ä»¶ï¼‰ã€‚æ¨å¥¨ï¼šgpt-4o-mini / ä»£æ›¿ï¼šgpt-3.5-turbo
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"question": text})

# ====== å®Ÿè¡Œ ======
if st.button("å›ç­”ã‚’ç”Ÿæˆ"):
    if not user_text.strip():
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                answer = ask_llm(user_text, role)
                st.success("å›ç­”")
                st.write(answer)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ä½¿ã„æ–¹ã®æ˜ç¤ºï¼ˆæ¡ä»¶ï¼šæ¦‚è¦/æ“ä½œèª¬æ˜ï¼‰
with st.expander("ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦ / ä½¿ã„æ–¹"):
    st.markdown(
        """
- å…¥åŠ›æ¬„ã«è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã‚’è¨˜å…¥  
- ã€Œå°‚é–€å®¶ã€ã‚’é¸ã³ **å›ç­”ã‚’ç”Ÿæˆ** ã‚’ã‚¯ãƒªãƒƒã‚¯  
- å½¹å‰²ã«å¿œã˜ã¦ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ‡ã‚Šæ›¿ãˆã€LangChainçµŒç”±ã§OpenAIã«å•ã„åˆã‚ã›ã¾ã™  
- APIã‚­ãƒ¼ã¯ `.env` ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ï¼ˆGitHubã«ã¯å«ã‚ã¾ã›ã‚“ï¼‰
        """
    )
